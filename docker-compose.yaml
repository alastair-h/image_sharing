### docker-compose.yml ###

services:
  api:
    build:
      context: ./api
      dockerfile: docker/Dockerfile.build
    command:  ["uvicorn", "src.app:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
    volumes:
      - ./api/:/app  # TODO: use only necessary volumes
    ports:
      - "8000:8000"
    environment:
      DEBUG: "1"
      POSTGRES_DB: image_sharing_db
      POSTGRES_USER: image_sharing_user
      POSTGRES_PASSWORD: image_sharing_password
      POSTGRES_HOST: db
      POSTGRES_PORT: "5432"

    depends_on:
      - db  # TODO: depends on ai


  inference_service:
    build:
      context: ./inference_service
      dockerfile: docker/Dockerfile.build
    command: ["uvicorn", "src.app:app", "--host", "0.0.0.0", "--port", "9000", "--reload"]
    volumes:
      - ./inference_service/:/app  # TODO: use only necessary volumes
    ports:
      - "9000:9000"
    environment:
      MODEL_URL:  "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4"
      LABELS_URL: "https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt"
      OPENAI_API_KEY: "openapikey"
      TFHUB_CACHE_DIR: "/app/model_cache"

  db:
    image: postgres:15
    volumes:
      - image_sharing_postgres_data:/var/lib/postgresql/custom_data
    environment:
      - POSTGRES_DB=image_sharing_db
      - POSTGRES_USER=image_sharing_user
      - POSTGRES_PASSWORD=image_sharing_password

volumes:
  image_sharing_postgres_data:
